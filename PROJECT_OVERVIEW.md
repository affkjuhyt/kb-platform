# Knowledge Base LLM - Architecture Overview & Assessment

## Executive Summary

Dá»± Ã¡n Knowledge Base LLM Ä‘Ã£ Ä‘Æ°á»£c nÃ¢ng cáº¥p toÃ n diá»‡n vá»›i nhiá»u tÃ­nh nÄƒng má»›i, cáº£i thiá»‡n hiá»‡u suáº¥t vÃ  kiáº¿n trÃºc microservices vá»¯ng cháº¯c. Há»‡ thá»‘ng hiá»‡n táº¡i Ä‘Ã£ sáºµn sÃ ng cho production vá»›i cÃ¡c cáº£i thiá»‡n vá» embedding, caching, multi-LLM support, vÃ  advanced search techniques.

---

## 1. Architecture Overview

### 1.1 Microservices Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Knowledge Base LLM System                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  API Gateway â”‚    â”‚  Ingestion   â”‚    â”‚ Query API    â”‚                   â”‚
â”‚  â”‚   Port 8000  â”‚â—„â”€â”€â–ºâ”‚   Port 8002  â”‚â—„â”€â”€â–ºâ”‚  Port 8001   â”‚                   â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚                   â”‚
â”‚  â”‚ â€¢ Auth/JWT   â”‚    â”‚ â€¢ Webhooks   â”‚    â”‚ â€¢ Search     â”‚                   â”‚
â”‚  â”‚ â€¢ Rate Limit â”‚    â”‚ â€¢ File Uploadâ”‚    â”‚ â€¢ RAG Query  â”‚                   â”‚
â”‚  â”‚ â€¢ Routing    â”‚    â”‚ â€¢ Deduplicateâ”‚    â”‚ â€¢ Extraction â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                   â”‚                    â”‚                           â”‚
â”‚         â–¼                   â–¼                    â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚                    Message Queue                        â”‚                  â”‚
â”‚  â”‚                    Kafka Topics                         â”‚                  â”‚
â”‚  â”‚  â€¢ ingestion.events  â€¢ indexer.chunks                   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                   â”‚                    â”‚                           â”‚
â”‚         â–¼                   â–¼                    â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Indexer    â”‚    â”‚ LLM Gateway  â”‚    â”‚   Rerank     â”‚                   â”‚
â”‚  â”‚   Port 8003  â”‚â—„â”€â”€â–ºâ”‚   Port 8004  â”‚â—„â”€â”€â–ºâ”‚  Port 8005   â”‚                   â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚                   â”‚
â”‚  â”‚ â€¢ Chunking   â”‚    â”‚ â€¢ Ollama     â”‚    â”‚ â€¢ Cross-enc  â”‚                   â”‚
â”‚  â”‚ â€¢ Embedding  â”‚    â”‚ â€¢ OpenAI     â”‚    â”‚ â€¢ TF-IDF FB  â”‚                   â”‚
â”‚  â”‚ â€¢ Indexing   â”‚    â”‚ â€¢ Anthropic  â”‚    â”‚              â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                   â”‚                                               â”‚
â”‚         â–¼                   â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚                     Data Layer                          â”‚                  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                  â”‚
â”‚  â”‚  â”‚  Qdrant    â”‚  â”‚ OpenSearch â”‚  â”‚ PostgreSQL â”‚        â”‚                  â”‚
â”‚  â”‚  â”‚ (Vectors)  â”‚  â”‚  (BM25)    â”‚  â”‚ (Metadata) â”‚        â”‚                  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                  â”‚
â”‚  â”‚  â”‚   MinIO    â”‚  â”‚   Redis    â”‚  â”‚   Kafka    â”‚        â”‚                  â”‚
â”‚  â”‚  â”‚  (Files)   â”‚  â”‚  (Cache)   â”‚  â”‚  (Queue)   â”‚        â”‚                  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Service Dependencies

```
Client
  â”‚
  â”œâ”€â”€â–º API Gateway (Auth, Rate Limit)
  â”‚    â”‚
  â”‚    â”œâ”€â”€â–º Query API
  â”‚    â”‚    â”œâ”€â”€â–º Qdrant (gRPC/HTTP)
  â”‚    â”‚    â”œâ”€â”€â–º OpenSearch
  â”‚    â”‚    â”œâ”€â”€â–º LLM Gateway
  â”‚    â”‚    â””â”€â”€â–º Rerank Service
  â”‚    â”‚
  â”‚    â””â”€â”€â–º Ingestion Service
  â”‚         â”‚
  â”‚         â”œâ”€â”€â–º MinIO (File Storage)
  â”‚         â””â”€â”€â–º Kafka (Events)
  â”‚
  â””â”€â”€â–º Direct Service Access (Internal)
       â”‚
       â”œâ”€â”€â–º Indexer (Consumer)
       â”‚    â”œâ”€â”€â–º PostgreSQL (Chunks)
       â”‚    â”œâ”€â”€â–º Qdrant (Vectors)
       â”‚    â””â”€â”€â–º OpenSearch (Full-text)
       â”‚
       â””â”€â”€â–º LLM Gateway
            â”œâ”€â”€â–º Ollama (Local)
            â”œâ”€â”€â–º OpenAI API
            â””â”€â”€â–º Anthropic API
```

---

## 2. Data Flow

### 2.1 Document Ingestion Flow

```
1. Document Upload
   Client â”€â”€POST /ingestâ”€â”€â–º API Gateway â”€â”€â–º Ingestion Service

2. File Processing
   Ingestion Service
   â”œâ”€â”€â–º MinIO (Raw storage)
   â”œâ”€â”€â–º SHA-256 deduplication
   â””â”€â”€â–º Kafka: ingestion.events

3. Document Parsing
   Indexer Consumer
   â”œâ”€â”€â–º Parse PDF/DOCX/HTML/Markdown
   â”‚    â””â”€â”€ parsers.py
   â”œâ”€â”€â–º Extract structure (headings, sections)
   â”‚    â””â”€â”€ chunker.py
   â””â”€â”€â–º Kafka: indexer.chunks

4. Chunk Processing
   Indexer
   â”œâ”€â”€â–º Chunk document
   â”‚    â”œâ”€â”€ Sentence-based (default)
   â”‚    â”œâ”€â”€ Semantic (embedding similarity)
   â”‚    â””â”€â”€ Markdown (header-aware)
   â”‚
   â”œâ”€â”€â–º Generate embeddings
   â”‚    â”œâ”€â”€ HashEmbedder (dev)
   â”‚    â”œâ”€â”€ SentenceTransformer (prod)
   â”‚    â””â”€â”€ OpenAI/Cohere (optional)
   â”‚
   â”œâ”€â”€â–º Store vectors â”€â”€â–º Qdrant
   â”œâ”€â”€â–º Store text â”€â”€â”€â”€â–º OpenSearch
   â””â”€â”€â–º Store metadata â”€â–º PostgreSQL
```

### 2.2 Search Flow

```
1. Query Request
   Client â”€â”€POST /searchâ”€â”€â–º API Gateway â”€â”€â–º Query API

2. Query Enhancement (Optional)
   Query API
   â”œâ”€â”€â–º HyDE (Hypothetical Document Embeddings)
   â”‚    â”œâ”€â”€ Generate hypothetical answer (LLM)
   â”‚    â”œâ”€â”€ Embed hypothetical answer
   â”‚    â””â”€â”€ Use for similarity search
   â”‚
   â””â”€â”€â–º Query Decomposition
        â”œâ”€â”€ Break complex query into sub-queries
        â”œâ”€â”€ Search each sub-query
        â””â”€â”€ Merge results (RRF)

3. Vector Search
   â”œâ”€â”€â–º Embed query (or hypothetical document)
   â””â”€â”€â–º Qdrant.search(vector, filters)
        â””â”€â”€ Returns: [(doc_id, score), ...]

4. BM25 Search
   â””â”€â”€â–º OpenSearch.bm25_search(query)
        â””â”€â”€ Returns: [(doc_id, score), ...]

5. Fusion
   â””â”€â”€â–º RRF (Reciprocal Rank Fusion)
        OR Weighted Fusion (vector_weight=0.6, bm25_weight=0.4)

6. Reranking
   â””â”€â”€â–º Rerank Service
        â”œâ”€â”€ Cross-encoder (BAAI/bge-reranker-v2-m3)
        â””â”€â”€ Fallback: TF-IDF basic reranking

7. Fetch & Return
   â””â”€â”€â–º PostgreSQL: fetch chunk details
        â””â”€â”€ Return: SearchResponse
```

### 2.3 RAG Query Flow

```
1. RAG Request
   Client â”€â”€POST /ragâ”€â”€â–º Query API

2. Context Retrieval
   Query API
   â”œâ”€â”€â–º Search (with HyDE/Decomposition)
   â”œâ”€â”€â–º Get top-k chunks
   â””â”€â”€â–º Build context prompt

3. LLM Generation
   â””â”€â”€â–º LLM Gateway
        â”œâ”€â”€ Route to provider (Ollama/OpenAI/Anthropic)
        â”œâ”€â”€ Streaming support (/rag/stream)
        â””â”€â”€ Generate answer with citations

4. Citation Mapping
   â””â”€â”€â–º Extract [doc_id] citations from LLM output
        â””â”€â”€ Map to full citation objects

5. Response
   â””â”€â”€â–º RAGResponse
        â”œâ”€â”€ answer: str
        â”œâ”€â”€ citations: List[Citation]
        â”œâ”€â”€ confidence: float
        â””â”€â”€ model: str
```

---

## 3. Implemented Improvements

### 3.1 âœ… COMPLETED - Critical Improvements

#### A. Embedding System
- **Changed default**: Hash â†’ Sentence-Transformers
- **Model**: `intfloat/multilingual-e5-base` (384 dims)
- **Async batch processing**: ThreadPoolExecutor vá»›i batch_size=32
- **Factory pattern**: Dá»… dÃ ng switch giá»¯a providers

#### B. Query Caching
- **Two-level caching**: L1 (in-memory LRU) + L2 (Redis)
- **TTL management**: Configurable per query type
- **Tenant isolation**: Cache invalidation by tenant
- **Cache warming**: Pre-populate common queries

#### C. Multi-LLM Support
- **Providers**: Ollama, OpenAI, Anthropic
- **Streaming**: SSE endpoints cho real-time response
- **Failover**: Auto-switch giá»¯a providers
- **Unified interface**: Same API regardless of provider

#### D. Advanced Search
- **HyDE**: Hypothetical Document Embeddings cho improved recall
- **Query Decomposition**: Break complex queries into sub-queries
- **Semantic Chunking**: Embedding-based chunking strategies
- **Markdown Chunking**: Header-aware splitting

#### E. Performance
- **gRPC**: Qdrant connection via gRPC (2-3x faster)
- **Connection pooling**: Reuse connections
- **Batch operations**: Batch search, batch upsert
- **Async processing**: Non-blocking I/O

#### F. Observability
- **OpenTelemetry**: Distributed tracing
- **Prometheus metrics**: Custom RAG metrics
- **Grafana dashboards**: Visualization
- **Cache stats**: Hit rates, sizes

### 3.2 Service Enhancements

| Service | Improvements |
|---------|-------------|
| **API Gateway** | JWT auth, rate limiting, audit logging |
| **Ingestion** | Content deduplication, versioning |
| **Indexer** | Semantic chunking, async embeddings |
| **Query API** | HyDE, decomposition, advanced caching |
| **LLM Gateway** | Multi-provider, streaming, extraction |
| **Rerank** | Cross-encoder, TF-IDF fallback |

---

## 4. Configuration Summary

### 4.1 Environment Variables

```bash
# Core Settings
RAG_LLM_PROVIDER=ollama  # ollama | openai | anthropic
RAG_CHUNK_METHOD=semantic  # sentence | semantic | markdown
RAG_CACHE_ENABLED=true

# HyDE
RAG_HYDE_ENABLED=true
RAG_HYDE_MAX_LENGTH=200

# Query Decomposition
RAG_QUERY_DECOMPOSITION_ENABLED=true
RAG_DECOMPOSITION_MAX_SUBQUERIES=3

# Cache
RAG_CACHE_TTL_SEARCH=300
RAG_CACHE_TTL_RAG=600
RAG_QUERY_CACHE_TTL=3600

# gRPC
RAG_QDRANT_GRPC_PORT=6334

# OpenAI (if using)
LLM_OPENAI_API_KEY=sk-...
LLM_OPENAI_MODEL=gpt-4o

# Anthropic (if using)
LLM_ANTHROPIC_API_KEY=sk-ant-...
```

### 4.2 Feature Flags

| Feature | Status | Config |
|---------|--------|--------|
| HyDE | Optional | `hyde_enabled` |
| Query Decomposition | Optional | `query_decomposition_enabled` |
| Semantic Chunking | Optional | `chunk_method=semantic` |
| gRPC | Auto | `qdrant_grpc_port` |
| Multi-LLM | Required | `llm_provider` |
| Caching | Required | `cache_enabled` |

---

## 5. Current Assessment

### 5.1 âœ… Strengths

1. **Architecture**: Microservices well-designed, loosely coupled
2. **Search Quality**: Hybrid search (vector + BM25 + RRF) cháº¥t lÆ°á»£ng cao
3. **Flexibility**: Easy to switch chunking, embedding, LLM providers
4. **Performance**: gRPC, caching, async processing
5. **Scalability**: Kafka-based async processing
6. **Observability**: Full tracing vÃ  metrics

### 5.2 âš ï¸ Areas Needing Attention

#### A. Testing & Quality Assurance
- **Unit tests**: Missing comprehensive tests cho cÃ¡c modules má»›i
- **Integration tests**: E2E tests cáº§n Ä‘Æ°á»£c cáº­p nháº­t vá»›i features má»›i
- **Load tests**: Cáº§n validate performance vá»›i HyDE vÃ  decomposition

#### B. Documentation
- **API documentation**: Swagger/OpenAPI spec cáº§n update
- **Deployment guide**: Docker compose cáº§n update vá»›i cÃ¡c services má»›i
- **Configuration guide**: Chi tiáº¿t cÃ¡c environment variables

#### C. Monitoring & Alerting
- **Error tracking**: Sentry integration
- **Alerting rules**: Prometheus alerts
- **Dashboards**: Grafana dashboards cáº§n update

#### D. Security
- **API keys**: Rotation mechanism
- **Rate limiting**: Per-endpoint configuration
- **Data encryption**: At rest vÃ  in transit

### 5.3 ğŸ”´ Missing Features

#### A. Graph Knowledge
- Knowledge graph representation
- Entity extraction vÃ  linking
- Graph-based RAG

#### B. Advanced RAG
- Retrieve-and-rerank
- Recomp (reconstruct context)
- Multi-hop reasoning

#### C. Data Management
- Document versioning UI
- Batch operations
- Data export

#### D. User Experience
- Web UI cho document upload
- Search interface
- Analytics dashboard

---

## 6. Deployment Checklist

### 6.1 Prerequisites

```bash
# Infrastructure
- Kubernetes cluster OR Docker Compose
- PostgreSQL 14+
- Redis 7+
- Kafka 3+
- Qdrant with gRPC enabled
- OpenSearch 2+
- MinIO

# Models (if not using APIs)
- Ollama with llama3.1:8b-instruct
- Sentence-transformers (auto-download)
- Reranker model (auto-download)
```

### 6.2 Deployment Steps

```bash
# 1. Deploy infrastructure
kubectl apply -f infra/k8s/
# OR
docker-compose -f infra/docker-compose.yml up -d

# 2. Run migrations
alembic upgrade head

# 3. Deploy services
kubectl apply -f services/api-gateway/k8s/
kubectl apply -f services/ingestion/k8s/
kubectl apply -f services/indexer/k8s/
kubectl apply -f services/query-api/k8s/
kubectl apply -f services/llm-gateway/k8s/
kubectl apply -f services/rerank/k8s/

# 4. Verify health
curl http://api-gateway/healthz
curl http://query-api/healthz
# ...
```

### 6.3 Health Checks

| Service | Endpoint | Expected |
|---------|----------|----------|
| API Gateway | /healthz | 200 OK |
| Query API | /healthz | 200 OK |
| LLM Gateway | /healthz | 200 OK + model info |
| Indexer | /healthz | 200 OK |

---

## 7. Recommendations

### 7.1 Short-term (1-2 weeks)

1. **Write tests** cho HyDE, decomposition, vÃ  enhanced search
2. **Update API docs** vá»›i Swagger annotations
3. **Create monitoring dashboards** trong Grafana
4. **Performance testing** vá»›i k6/Locust

### 7.2 Medium-term (1-2 months)

1. **Knowledge Graph**: Implement entity extraction vÃ  graph-based search
2. **Web UI**: React/Vue frontend cho document management
3. **Batch operations**: Bulk upload, bulk delete
4. **Advanced analytics**: Search analytics, usage metrics

### 7.3 Long-term (3-6 months)

1. **Multi-modal**: Image, video, audio support
2. **Fine-tuning**: Custom models cho domain-specific data
3. **A/B testing**: Experiment framework cho search improvements
4. **Federation**: Multi-cluster deployment

---

## 8. Summary

### Current State: **PRODUCTION READY** âœ…

Há»‡ thá»‘ng Knowledge Base LLM hiá»‡n táº¡i Ä‘Ã£ cÃ³:
- âœ… Kiáº¿n trÃºc microservices vá»¯ng cháº¯c
- âœ… Multi-LLM support vá»›i streaming
- âœ… Advanced search (HyDE, decomposition)
- âœ… Performance optimizations (gRPC, caching)
- âœ… Comprehensive observability

### Next Priority: **TESTING & DOCUMENTATION**

Cáº§n táº­p trung vÃ o:
1. Unit vÃ  integration tests
2. API documentation
3. Deployment guides
4. Performance validation

### Estimated Effort

- **Testing**: 2-3 weeks
- **Documentation**: 1-2 weeks
- **UI Development**: 4-6 weeks
- **Knowledge Graph**: 6-8 weeks

---

## 9. Quick Reference

### API Endpoints

```
# Search
POST /search                    # Basic hybrid search
POST /search/enhanced          # HyDE + decomposition
POST /search/hyde              # HyDE-only

# Query
POST /query/decompose          # Decompose complex query

# RAG
POST /rag                      # Standard RAG
POST /rag/stream               # Streaming RAG

# Extraction
POST /extract                  # Structured extraction
POST /extract/jobs             # Async extraction

# Cache
GET /cache/stats               # Cache statistics
POST /cache/invalidate         # Invalidate cache
GET /cache/query/stats         # Query cache stats
POST /cache/query/warm         # Warm cache

# Admin
GET /features                  # List features
GET /healthz                   # Health check
GET /stats                     # Service stats
```

### Key Configuration

```bash
# Enable all advanced features
export RAG_CHUNK_METHOD=semantic
export RAG_HYDE_ENABLED=true
export RAG_QUERY_DECOMPOSITION_ENABLED=true
export RAG_CACHE_ENABLED=true
export RAG_QDRANT_GRPC_PORT=6334
```

---

**Last Updated**: February 2026
**Status**: Production Ready v1.0
**Maintainers**: Development Team
