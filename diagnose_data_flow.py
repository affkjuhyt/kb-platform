#!/usr/bin/env python3
"""
Diagnostic script to check data flow: Ingestion -> Indexer -> Qdrant

This script checks:
1. Documents in PostgreSQL
2. Documents in MinIO
3. Chunks in Qdrant
4. Indexer consumer status
"""

import sys
import os

sys.path.insert(0, "/Users/thiennlinh/Documents/New project/services/ingestion")
sys.path.insert(0, "/Users/thiennlinh/Documents/New project/services/indexer")

print("=" * 80)
print("DATA FLOW DIAGNOSTIC")
print("Checking: Ingestion -> PostgreSQL -> Indexer -> Qdrant")
print("=" * 80)

# Check 1: PostgreSQL
try:
    print("\nüìä 1. Checking PostgreSQL (Documents)...")
    from ingestion.db import get_session
    from ingestion.models import Document
    from sqlalchemy import func

    with get_session() as session:
        doc_count = session.query(func.count(Document.id)).scalar()
        latest_docs = (
            session.query(Document).filter(Document.latest == True).limit(5).all()
        )

        print(f"   ‚úÖ Total documents: {doc_count}")
        print(f"   ‚úÖ Latest documents: {len([d for d in latest_docs])}")

        if latest_docs:
            print("\n   Recent documents:")
            for doc in latest_docs:
                print(
                    f"   - {doc.doc_id} (v{doc.version}): {doc.source}/{doc.source_id}"
                )

        if doc_count == 0:
            print("   ‚ö†Ô∏è  WARNING: No documents found in PostgreSQL!")
            print("      Run: curl -X POST http://localhost:8002/webhook ...")
except Exception as e:
    print(f"   ‚ùå ERROR: {e}")
    print("      Is PostgreSQL running? docker-compose ps")

# Check 2: MinIO
try:
    print("\nüì¶ 2. Checking MinIO (Raw Files)...")
    from ingestion.storage import storage_service_factory

    storage = storage_service_factory()
    client = storage._factory.create_s3_client()

    # List objects
    objects = client.list_objects_v2(Bucket="raw-docs")
    object_count = objects.get("KeyCount", 0)

    print(f"   ‚úÖ Objects in MinIO: {object_count}")

    if object_count > 0:
        print("   Sample objects:")
        for obj in objects.get("Contents", [])[:3]:
            print(f"   - {obj['Key']} ({obj['Size']} bytes)")

    if object_count == 0:
        print("   ‚ö†Ô∏è  WARNING: No files in MinIO!")
except Exception as e:
    print(f"   ‚ùå ERROR: {e}")
    print("      Is MinIO running? docker logs kb-minio")

# Check 3: Qdrant
try:
    print("\nüîç 3. Checking Qdrant (Vector Chunks)...")
    from qdrant_client import QdrantClient
    from indexer.config import settings

    client = QdrantClient(url=settings.qdrant_url)

    # Check collection
    collections = client.get_collections()
    collection_names = [c.name for c in collections.collections]

    print(f"   ‚úÖ Collections: {collection_names}")

    if settings.qdrant_collection in collection_names:
        collection_info = client.get_collection(settings.qdrant_collection)
        vectors_count = collection_info.points_count
        print(
            f"   ‚úÖ Collection '{settings.qdrant_collection}': {vectors_count} vectors"
        )

        if vectors_count == 0:
            print("   ‚ö†Ô∏è  WARNING: Collection exists but has no vectors!")
            print("      Indexer consumer might not be processing messages.")
    else:
        print(f"   ‚ùå ERROR: Collection '{settings.qdrant_collection}' NOT FOUND!")
        print("      Indexer should create this automatically.")
        print("      Or create manually with the indexer service.")
except Exception as e:
    print(f"   ‚ùå ERROR: {e}")
    print("      Is Qdrant running? docker logs kb-qdrant")

# Check 4: Kafka
try:
    print("\nüì® 4. Checking Kafka (Message Queue)...")
    from kafka import KafkaConsumer

    consumer = KafkaConsumer(
        bootstrap_servers="localhost:9092", consumer_timeout_ms=5000
    )

    topics = consumer.topics()
    print(f"   ‚úÖ Available topics: {len(topics)}")

    if "ingestion.events" in topics:
        print("   ‚úÖ Topic 'ingestion.events' exists")
    else:
        print("   ‚ö†Ô∏è  WARNING: Topic 'ingestion.events' not found!")

    if "indexer.chunks" in topics:
        print("   ‚úÖ Topic 'indexer.chunks' exists")
    else:
        print("   ‚ö†Ô∏è  WARNING: Topic 'indexer.chunks' not found!")

    consumer.close()
except Exception as e:
    print(f"   ‚ùå ERROR: {e}")
    print("      Is Kafka running? docker logs kb-kafka")

# Check 5: Indexer Consumer
try:
    print("\n‚öôÔ∏è  5. Checking Indexer Consumer...")
    import subprocess

    result = subprocess.run(
        [
            "docker",
            "ps",
            "--filter",
            "name=kb-indexer",
            "--format",
            "{{.Names}}: {{.Status}}",
        ],
        capture_output=True,
        text=True,
    )

    if result.stdout.strip():
        print(f"   ‚úÖ Indexer containers:")
        for line in result.stdout.strip().split("\n"):
            print(f"      {line}")
    else:
        print("   ‚ùå ERROR: No indexer containers found!")
        print("      Start with: docker-compose up -d indexer indexer-consumer")
except Exception as e:
    print(f"   ‚ö†Ô∏è  Could not check Docker: {e}")

# Summary
print("\n" + "=" * 80)
print("SUMMARY")
print("=" * 80)

print("\nData Flow Status:")
print("  1. Ingestion Service  ‚Üí PostgreSQL (Documents)")
print("  2. PostgreSQL         ‚Üí MinIO (Raw Files)")
print("  3. Kafka              ‚Üí Message Queue")
print("  4. Indexer Consumer   ‚Üí Qdrant (Vectors)")
print("  5. Query API          ‚Üê Qdrant (Search)")

print("\nCommon Issues:")
print("  ‚ùå 'Collection doesn't exist' ‚Üí Indexer not creating collection")
print("  ‚ùå 'No vectors' ‚Üí Indexer consumer not processing messages")
print("  ‚ùå 'Connection refused' ‚Üí Service not running")

print("\nQuick Fixes:")
print("  1. Restart indexer: docker-compose restart indexer indexer-consumer")
print("  2. Check logs: docker logs -f kb-indexer-consumer")
print("  3. Manual index: python services/indexer/manual_index.py")

print("\n" + "=" * 80)
